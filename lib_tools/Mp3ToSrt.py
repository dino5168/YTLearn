import whisper
from pathlib import Path
import sys
import os
from typing import Optional, List


def format_timestamp(seconds: float) -> str:
    """æ ¼å¼åŒ–æ™‚é–“æˆ³è¨˜ç‚º SRT æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds - int(seconds)) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def write_srt(segments, file_path: str) -> bool:
    """å°‡è½‰éŒ„çµæœå¯«å…¥ SRT æª”æ¡ˆ"""
    try:
        output_dir = Path(file_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)

        with open(file_path, "w", encoding="utf-8") as f:
            for i, segment in enumerate(segments, start=1):
                start = format_timestamp(segment["start"])
                end = format_timestamp(segment["end"])
                text = segment["text"].strip()
                f.write(f"{i}\n{start} --> {end}\n{text}\n\n")
        return True
    except Exception as e:
        print(f"âŒ å¯«å…¥ SRT ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return False


def get_available_models() -> List[str]:
    """å–å¾—å¯ç”¨çš„ Whisper æ¨¡å‹"""
    return ["tiny", "base", "small", "medium", "large"]


def get_supported_languages() -> dict:
    """å–å¾—æ”¯æ´çš„èªè¨€ä»£ç¢¼"""
    return {
        "en": "English",
        "zh": "Chinese",
        "ja": "Japanese",
        "ko": "Korean",
        "es": "Spanish",
        "fr": "French",
        "de": "German",
        "it": "Italian",
        "pt": "Portuguese",
        "ru": "Russian",
        "ar": "Arabic",
        "hi": "Hindi",
        "auto": "è‡ªå‹•åµæ¸¬",
    }


def validate_audio_file(file_path: str) -> bool:
    """é©—è­‰éŸ³è¨Šæª”æ¡ˆæ˜¯å¦å­˜åœ¨ä¸”ç‚ºæ”¯æ´æ ¼å¼"""
    path = Path(file_path)
    if not path.exists():
        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨ï¼š{file_path}")
        return False

    supported_formats = {
        ".mp3",
        ".wav",
        ".m4a",
        ".flac",
        ".ogg",
        ".opus",
        ".mp4",
        ".avi",
        ".mov",
        ".mkv",
    }
    if path.suffix.lower() not in supported_formats:
        print(f"âš ï¸  è­¦å‘Šï¼šæª”æ¡ˆæ ¼å¼ {path.suffix} å¯èƒ½ä¸å—æ”¯æ´")
        print(f"   æ”¯æ´æ ¼å¼ï¼š{', '.join(supported_formats)}")
        return input("æ˜¯å¦ç¹¼çºŒï¼Ÿ(y/N): ").lower() == "y"

    return True


def transcribe_to_srt(
    audio_path: str,
    output_path: Optional[str] = None,
    model_name: str = "base",
    language: str = "en",
) -> bool:
    """
    å°‡éŸ³è¨Šè½‰éŒ„ç‚ºå­—å¹•ï¼ˆSRTï¼‰ï¼Œä¸¦å„²å­˜è‡³æŒ‡å®šæª”æ¡ˆã€‚

    åƒæ•¸:
        audio_path: éŸ³è¨Šæª”æ¡ˆè·¯å¾‘
        output_path: è¼¸å‡º SRT è·¯å¾‘ï¼ˆå¯é¸ï¼‰
        model_name: Whisper æ¨¡å‹åç¨±ï¼ˆtiny/base/small/medium/largeï¼‰
        language: æŒ‡å®šèªè¨€ä»£ç¢¼ï¼ˆä¾‹å¦‚ "zh", "en", "auto"ï¼‰

    å›å‚³:
        æˆåŠŸç‚º Trueï¼Œå¤±æ•—ç‚º False
    """
    audio_path = Path(audio_path)

    if not validate_audio_file(str(audio_path)):
        return False

    if output_path is None:
        output_path = str(audio_path.with_suffix(".srt"))

    print(f"ğŸ“‚ éŸ³è¨Šæª”æ¡ˆï¼š{audio_path}")
    print(f"ğŸ“ è¼¸å‡ºæª”æ¡ˆï¼š{output_path}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹ï¼š{model_name}")
    print(f"ğŸŒ æŒ‡å®šèªè¨€ï¼š{language}")
    print("-" * 50)

    try:
        print("ğŸ”„ è¼‰å…¥æ¨¡å‹ä¸­...")
        model = whisper.load_model(model_name)
        print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—ï¼š{e}")
        return False

    try:
        print("ğŸµ é–‹å§‹è½‰éŒ„...")
        transcribe_params = {"verbose": True}
        if language != "auto":
            transcribe_params["language"] = language

        result = model.transcribe(str(audio_path), **transcribe_params)
        print("âœ… è½‰éŒ„å®Œæˆ")
    except Exception as e:
        print(f"âŒ è½‰éŒ„å¤±æ•—ï¼š{e}")
        return False

    success = write_srt(result["segments"], output_path)
    if success:
        print(f"âœ… å­—å¹•å·²å„²å­˜ï¼š{output_path}")
        print(f"   ğŸ” åµæ¸¬èªè¨€ï¼š{result.get('language', 'æœªçŸ¥')}")
        print(f"   â±ï¸  éŸ³è¨Šé•·åº¦ï¼š{format_timestamp(result.get('duration', 0))}")
        print(f"   ğŸ“Š å­—å¹•ç‰‡æ®µæ•¸ï¼š{len(result['segments'])}")

    return success


def interactive_mode():
    """äº¤è«‡å¼æ¨¡å¼"""
    print("ğŸ¤ Whisper éŸ³è¨Šè½‰éŒ„å·¥å…·")
    print("=" * 50)

    while True:
        print("\nğŸ“ è«‹è¼¸å…¥éŸ³è¨Šæª”æ¡ˆè·¯å¾‘ï¼ˆæˆ– 'q' é€€å‡ºï¼‰:")
        audio_path = input(">>> ").strip()

        if audio_path.lower() in ["q", "quit", "exit"]:
            print("ğŸ‘‹ å†è¦‹ï¼")
            break

        if not audio_path:
            print("âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„æª”æ¡ˆè·¯å¾‘")
            continue

        # è™•ç†å¼•è™ŸåŒ…åœçš„è·¯å¾‘
        if audio_path.startswith('"') and audio_path.endswith('"'):
            audio_path = audio_path[1:-1]

        if not validate_audio_file(audio_path):
            continue

        # é¸æ“‡æ¨¡å‹
        models = get_available_models()
        print(f"\nğŸ¤– é¸æ“‡æ¨¡å‹ (é è¨­: base):")
        for i, model in enumerate(models):
            print(f"  {i+1}. {model}")

        model_choice = input(">>> ").strip()
        if model_choice.isdigit() and 1 <= int(model_choice) <= len(models):
            model_name = models[int(model_choice) - 1]
        elif model_choice in models:
            model_name = model_choice
        else:
            model_name = "base"

        # é¸æ“‡èªè¨€
        languages = get_supported_languages()
        print(f"\nğŸŒ é¸æ“‡èªè¨€ (é è¨­: en):")
        for code, name in languages.items():
            print(f"  {code}: {name}")

        lang_choice = input(">>> ").strip().lower()
        if lang_choice in languages:
            language = lang_choice
        else:
            language = "en"

        # è¼¸å‡ºè·¯å¾‘
        print(f"\nğŸ“ è¼¸å‡ºè·¯å¾‘ (é è¨­: èˆ‡éŸ³è¨Šæª”æ¡ˆåŒç›®éŒ„):")
        output_path = input(">>> ").strip()
        if output_path.startswith('"') and output_path.endswith('"'):
            output_path = output_path[1:-1]

        output_path = output_path if output_path else None

        # é–‹å§‹è½‰éŒ„
        print(f"\nğŸš€ é–‹å§‹è½‰éŒ„...")
        success = transcribe_to_srt(audio_path, output_path, model_name, language)

        if success:
            print("\nâœ… è½‰éŒ„å®Œæˆï¼")
        else:
            print("\nâŒ è½‰éŒ„å¤±æ•—")

        print("\n" + "=" * 50)


def main():
    """ä¸»ç¨‹å¼"""
    if len(sys.argv) == 1:
        # æ²’æœ‰åƒæ•¸æ™‚å•Ÿå‹•äº¤è«‡å¼æ¨¡å¼
        interactive_mode()
    else:
        # å‘½ä»¤åˆ—æ¨¡å¼
        if len(sys.argv) < 2:
            print("ç”¨æ³•: python script.py <éŸ³è¨Šæª”æ¡ˆ> [è¼¸å‡ºè·¯å¾‘] [æ¨¡å‹] [èªè¨€]")
            print("æˆ–ç›´æ¥åŸ·è¡Œé€²å…¥äº¤è«‡å¼æ¨¡å¼")
            return

        audio_path = sys.argv[1]
        output_path = sys.argv[2] if len(sys.argv) > 2 else None
        model_name = sys.argv[3] if len(sys.argv) > 3 else "base"
        language = sys.argv[4] if len(sys.argv) > 4 else "en"

        success = transcribe_to_srt(audio_path, output_path, model_name, language)
        sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
