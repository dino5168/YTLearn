from datetime import timedelta
import os
import re
from googletrans import Translator
import requests
from yt_dlp import YoutubeDL


async def download_mp3_from_info(info: dict, output_dir: str) -> str:
    """æ ¹æ“šå·²å–å¾—çš„ info å­—å…¸ä¸‹è¼‰ MP3 éŸ³è¨Š"""
    video_id = info.get("id", "audio")
    output_filename = f"{video_id}.mp3"
    output_path = os.path.join(output_dir, output_filename)

    ydl_opts = {
        "format": "bestaudio/best",
        "postprocessors": [
            {
                "key": "FFmpegExtractAudio",
                "preferredcodec": "mp3",
                "preferredquality": "192",
            }
        ],
        "outtmpl": os.path.join(output_dir, f"temp_{video_id}.%(ext)s"),
        "quiet": True,
    }

    try:
        with YoutubeDL(ydl_opts) as ydl:
            # ç”¨åŸå§‹ URL å†ä¸‹è¼‰éŸ³è¨Š
            ydl.download([info["webpage_url"]])

        # æ‰¾å‡ºå¯¦éš›çš„ä¸‹è¼‰æª”æ¡ˆ
        temp_path = os.path.join(output_dir, f"temp_{video_id}.mp3")
        if os.path.exists(temp_path):
            os.rename(temp_path, output_path)
            print(f"âœ… éŸ³è¨Šå·²ä¸‹è¼‰ä¸¦å„²å­˜ç‚ºï¼š{output_path}")
            return output_path

        print("âŒ æ‰¾ä¸åˆ° mp3 æª”æ¡ˆ")
        return ""
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰ MP3 éŒ¯èª¤: {e}")
        raise


async def download_thumbnail_from_info(
    info: dict, output_dir: str, use_video_id: bool = True
) -> str:
    """å¾å·²å–å¾—çš„ info å­—å…¸ä¸‹è¼‰ç¸®åœ–åœ–ç‰‡"""

    thumbnail_url = info.get("thumbnail", "")
    video_id = info.get("id", "thumbnail")

    if not thumbnail_url:
        print("âŒ ç„¡æ³•å–å¾—ç¸®åœ–ç¶²å€")
        return ""

    # åˆ¤æ–·å‰¯æª”å
    ext = "jpg"
    for t in [".jpeg", ".png", ".webp"]:
        if t in thumbnail_url.lower():
            ext = t.strip(".")
            break
    if ext == "webp":
        ext = "jpg"

    filename = f"{video_id}.{ext}" if use_video_id else f"thumbnail.{ext}"
    output_path = os.path.join(output_dir, filename)

    try:
        print(f"ğŸ–¼ ä¸‹è¼‰ç¸®åœ–ä¸­ï¼š{thumbnail_url}")
        response = requests.get(thumbnail_url, stream=True, timeout=30)
        response.raise_for_status()

        with open(output_path, "wb") as f:
            for chunk in response.iter_content(8192):
                f.write(chunk)

        print(f"âœ… ç¸®åœ–å·²å„²å­˜è‡³ï¼š{output_path}")
        return output_path

    except requests.RequestException as e:
        print(f"âŒ ç¶²è·¯éŒ¯èª¤: {e}")
        return ""
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰ç¸®åœ–ç™¼ç”ŸéŒ¯èª¤: {e}")
        return ""


def parse_timestamp(timestamp: str) -> float:
    """å°‡ SRT æ™‚é–“æ ¼å¼è½‰ç‚ºç§’æ•¸"""
    h, m, s_ms = timestamp.split(":")
    s, ms = s_ms.split(",")
    return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000


def format_timestamp(seconds: float) -> str:
    """å°‡ç§’æ•¸è½‰å› SRT æ™‚é–“æ ¼å¼"""
    td = timedelta(seconds=seconds)
    total_seconds = int(td.total_seconds())
    ms = int((td.total_seconds() - total_seconds) * 1000)
    h = total_seconds // 3600
    m = (total_seconds % 3600) // 60
    s = total_seconds % 60
    return f"{h:02}:{m:02}:{s:02},{ms:03}"


# è‹±æ–‡ä½¿ç”¨ ? å¯ä»¥å…ˆä¸ç”¨
def merge_srt_to_sentence_srt(input_srt_path: str, output_srt_path: str):
    with open(input_srt_path, "r", encoding="utf-8") as f:
        content = f.read()

    blocks = re.split(r"\n\s*\n", content.strip())

    merged_segments = []
    buffer_text = ""
    buffer_start = None
    buffer_end = None

    for block in blocks:
        lines = block.strip().splitlines()
        if len(lines) < 3:
            continue

        time_range = lines[1]
        text = " ".join(lines[2:]).strip()

        start_str, end_str = time_range.split(" --> ")
        start_sec = parse_timestamp(start_str)
        end_sec = parse_timestamp(end_str)

        if buffer_text == "":
            buffer_start = start_sec

        buffer_text += (" " if buffer_text else "") + text
        buffer_end = end_sec

        if re.search(r'[.!?]["â€]?$|\w\.\s*$', text):
            merged_segments.append((buffer_start, buffer_end, buffer_text.strip()))
            buffer_text = ""
            buffer_start = None
            buffer_end = None

    # æ®˜ç•™æœ€å¾Œä¸€å¥
    if buffer_text:
        merged_segments.append((buffer_start, buffer_end, buffer_text.strip()))

    # å¯«å…¥æ–°çš„ SRT æª”æ¡ˆ
    with open(output_srt_path, "w", encoding="utf-8") as f:
        for idx, (start, end, text) in enumerate(merged_segments, start=1):
            f.write(f"{idx}\n")
            f.write(f"{format_timestamp(start)} --> {format_timestamp(end)}\n")
            f.write(f"{text}\n\n")

    print(f"[è¼¸å‡ºå®Œæˆ] æ–°çš„åˆä½µå­—å¹•å·²å¯«å…¥ï¼š{output_srt_path}")


def translate_text(text, target_lang):
    translator = Translator()
    if not text.strip():
        return ""
    try:
        result = translator.translate(text, dest=target_lang)
        return result.text
    except Exception as e:
        print(f"âš ï¸ ç¿»è­¯å¤±æ•—: {e}")
        return ""


# ç¿»è­¯å­—å¹•
async def process_srt(input_path, output_path, target_lang):
    with open(input_path, "r", encoding="utf-8") as infile:
        lines = infile.readlines()

    output_lines = []
    buffer = []
    blocks = []
    for line in lines:
        if re.match(r"^\d+$", line.strip()):
            if buffer:
                blocks.append(list(buffer))
                buffer.clear()
        buffer.append(line)
    if buffer:
        blocks.append(list(buffer))

    total = len(blocks)
    for i, block in enumerate(blocks, start=1):
        output_lines.extend(process_block(block, target_lang))
        print(f"â³ è™•ç†é€²åº¦: {i}/{total} ({(i/total)*100:.1f}%)", end="\r")

    with open(output_path, "w", encoding="utf-8") as outfile:
        outfile.writelines(output_lines)


def process_block(block_lines, target_lang):
    result = []
    text_lines = []
    block_number = ""
    timecode_line = ""

    for line in block_lines:
        if line.strip().isdigit():
            block_number = line
        elif "-->" in line:
            timecode_line = line
        else:
            text_lines.append(line.strip())

    if text_lines:
        full_text = " ".join(text_lines)
        translated = translate_text(full_text, target_lang)
        # åˆä½µç‚ºå–®è¡Œå­—å¹•
        merged_line = f"{full_text}\n{translated}\n"
        result.extend([block_number, timecode_line, merged_line, "\n"])
    else:
        result.extend(block_lines)
        result.append("\n")

    return result


import torch
from faster_whisper import WhisperModel


def format_timestamp(seconds: float) -> str:
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    s = int(seconds % 60)
    ms = int((seconds - int(seconds)) * 1000)
    return f"{h:02}:{m:02}:{s:02},{ms:03}"


# medium
async def transcribe_mp3_to_srt(
    mp3_path: str, output_srt_path: str, model_size="small"
) -> dict:
    """ä½¿ç”¨ FasterWhisper å°‡ MP3 è½‰ç‚º SRT å­—å¹•"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"[FasterWhisper] åˆå§‹åŒ–æ¨¡å‹ {model_size} on {device}")

    model = WhisperModel(model_size, device=device, compute_type="int8")
    print(f"[FasterWhisper] é–‹å§‹è½‰éŒ„ï¼š{mp3_path}")
    segments, info = model.transcribe(mp3_path, beam_size=5)
    print(f"[FasterWhisper] åµæ¸¬èªè¨€ï¼š{info.language}")

    with open(output_srt_path, "w", encoding="utf-8") as f:
        for i, segment in enumerate(segments, start=1):
            f.write(f"{i}\n")
            f.write(
                f"{format_timestamp(segment.start)} --> {format_timestamp(segment.end)}\n"
            )
            f.write(f"{segment.text.strip()}\n\n")

    print(f"âœ… SRT å·²å„²å­˜ï¼š{output_srt_path}")
    return {"srt_path": output_srt_path, "lan": info.language}
